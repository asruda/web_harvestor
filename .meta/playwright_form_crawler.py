import asyncio
import os
import json
import re
import csv
from playwright.async_api import async_playwright

# å¯é€‰ä¾èµ– - pandas ç”¨äº Excel å¯¼å‡º
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

class PlaywrightFormCrawler:
    """
    åŸºäº Playwright çš„è¡¨å•æ“ä½œçˆ¬è™«ç±»
    """
    
    def __init__(self, login_url: str, target_url: str, user_data_dir: str = "./my_browser_session"):
        self.login_url = login_url
        self.target_url = target_url
        self.user_data_dir = user_data_dir
        
        # ç¡®ä¿ä¼šè¯ç›®å½•å­˜åœ¨
        os.makedirs(self.user_data_dir, exist_ok=True)
    
    async def crawl_with_form_operation(self, applicant_name: str = "é’å²›è¿ˆé‡‘æ™ºèƒ½ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸"):
        """
        æ‰§è¡Œæ‰‹åŠ¨ç™»å½•åçš„è¡¨å•æ“ä½œæµç¨‹
        è‡ªåŠ¨å¡«å†™ç”³è¯·äººä¿¡æ¯å¹¶æ‰§è¡ŒæŸ¥è¯¢
        """
        print("=" * 60)
        print("ğŸš€ Playwright è¡¨å•æ“ä½œçˆ¬è™«å¯åŠ¨")
        print("=" * 60)
        print(f"ğŸ“ ç™»å½•é¡µé¢: {self.login_url}")
        print(f"ğŸ¯ ç›®æ ‡é¡µé¢: {self.target_url}")
        print(f"ğŸ‘¤ ç”³è¯·äºº: {applicant_name}")
        print(f"ğŸ’¾ ä¼šè¯ä¿å­˜: {self.user_data_dir}")
        print("=" * 60)
        
        async with async_playwright() as p:
            # ä½¿ç”¨æŒä¹…åŒ–ä¸Šä¸‹æ–‡
            context = await p.chromium.launch_persistent_context(
                user_data_dir=self.user_data_dir,
                headless=False,
                args=[
                    '--remote-debugging-port=9222',
                    '--disable-gpu',
                    '--disable-gpu-compositing',
                    '--disable-software-rasterizer',
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--no-first-run',
                    '--no-default-browser-check',
                    '--disable-infobars',
                    '--window-position=0,0',
                    '--ignore-certificate-errors',
                    '--ignore-certificate-errors-spki-list',
                    '--disable-blink-features=AutomationControlled',
                    '--window-position=400,0',
                    '--disable-renderer-backgrounding',
                    '--disable-ipc-flooding-protection',
                    '--force-color-profile=srgb',
                    '--mute-audio',
                    '--disable-background-timer-throttling'
                ]
            )
            
            # è·å–ç¬¬ä¸€ä¸ªé¡µé¢
            page = context.pages[0] if context.pages else await context.new_page()
            
            try:
                # ç¬¬ä¸€æ­¥ï¼šå¯¼èˆªåˆ°ç™»å½•é¡µé¢
                print("\n1ï¸âƒ£ æ­£åœ¨æ‰“å¼€ç™»å½•é¡µé¢...")
                await page.goto(self.login_url, wait_until="networkidle")
                print("âœ… ç™»å½•é¡µé¢åŠ è½½æˆåŠŸ")
                print("ğŸ‘¤ è¯·åœ¨æµè§ˆå™¨çª—å£ä¸­æ‰‹åŠ¨å®Œæˆç™»å½•æ“ä½œ")
                print("â³ ç¨‹åºå°†ç­‰å¾…æ‚¨å®Œæˆç™»å½•...")
                
                # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•
                print("\n2ï¸âƒ£ ç­‰å¾…æ‰‹åŠ¨ç™»å½•...")
                print("ğŸ’¡ æç¤ºï¼šç™»å½•å®Œæˆåï¼Œè¯·ç¡®ä¿åœç•™åœ¨æŸ¥è¯¢é¡µé¢")
                print("â° æ™ºèƒ½ç­‰å¾…ä¸­ï¼Œæ£€æµ‹åˆ°ç™»å½•æˆåŠŸå°†ç«‹å³ç»§ç»­...")
                
                # æ™ºèƒ½ç­‰å¾…ç™»å½•å®Œæˆ - æ£€æŸ¥"æ¬¢è¿ä½ "ç­‰ç™»å½•æˆåŠŸæ ‡è¯†
                login_success = await self._wait_for_login_success(page)
                
                if not login_success:
                    print("âš ï¸ ç™»å½•ç­‰å¾…è¶…æ—¶")
                    return None
                else:
                    print("âœ… æ£€æµ‹åˆ°ç™»å½•æˆåŠŸï¼Œç«‹å³ç»§ç»­æ‰§è¡Œè¡¨å•æ“ä½œ...")
                
                # ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½ç­‰å¾…ç”³è¯·äººè¾“å…¥æ¡†å‡ºç°
                print("\n3ï¸âƒ£ æ­£åœ¨ç­‰å¾…ç”³è¯·äººè¾“å…¥æ¡†å‡ºç°...")
                applicant_input = await self._wait_for_applicant_input(page)
                
                if not applicant_input:
                    print("âŒ ç”³è¯·äººè¾“å…¥æ¡†æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²æ­£ç¡®ç™»å½•")
                    return None
                
                print("âœ… ç”³è¯·äººè¾“å…¥æ¡†å·²æ‰¾åˆ°")
                
                # ç¬¬å››æ­¥ï¼šå¡«å†™ç”³è¯·äººä¿¡æ¯
                print(f"\n4ï¸âƒ£ æ­£åœ¨å¡«å†™ç”³è¯·äººä¿¡æ¯: {applicant_name}")
                await page.evaluate("""
                    (name) => {
                        // XPath å®šä½å‡½æ•°
                        function findByXPath(xpath) {
                            try {
                                const result = document.evaluate(xpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null);
                                return result.singleNodeValue;
                            } catch (e) {
                                return null;
                            }
                        }
                        
                        // å¤šç­–ç•¥å®šä½ç”³è¯·äººè¾“å…¥æ¡†
                        const xpaths = [
                            "//div[normalize-space(text())='ç”³è¯·äººï¼š']/following-sibling::label[contains(@class, 'q-field')]//input[@type='text']",
                            "//div[contains(@class, 'q-item__label') and normalize-space(text())='ç”³è¯·äººï¼š']/following-sibling::label//input",
                            "//label[preceding-sibling::div[normalize-space(text())='ç”³è¯·äººï¼š']]//input[@type='text']",
                            "//div[contains(@class, 'row') and .//div[normalize-space(text())='ç”³è¯·äººï¼š']]//input[@type='text']"
                        ];
                        
                        for (let xpath of xpaths) {
                            const input = findByXPath(xpath);
                            if (input) {
                                input.value = name;
                                input.dispatchEvent(new Event('input', { bubbles: true }));
                                input.dispatchEvent(new Event('change', { bubbles: true }));
                                return true;
                            }
                        }
                        return false;
                    }
                """, applicant_name)
                print("âœ… ç”³è¯·äººä¿¡æ¯å·²å¡«å†™")
                
                # ç¬¬äº”æ­¥ï¼šç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
                print("\n5ï¸âƒ£ æ­£åœ¨ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®...")
                search_result = await self._click_search_button(page)
                
                if not search_result or not search_result.get('success'):
                    print("âŒ æŸ¥è¯¢æŒ‰é’®æœªæ‰¾åˆ°æˆ–ç‚¹å‡»å¤±è´¥")
                    if search_result:
                        print(f"ğŸ“‹ è°ƒè¯•ä¿¡æ¯: {search_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                        print(f"ğŸ“Š æ‰¾åˆ°çš„æŒ‰é’®æ•°é‡: {search_result.get('foundButtons', 0)}")
                    return None
                
                print("âœ… æŸ¥è¯¢æŒ‰é’®å·²ç‚¹å‡»")
                print(f"ğŸ’¡ ä½¿ç”¨çš„å®šä½ç­–ç•¥: {search_result.get('strategy', 'æœªçŸ¥')}")
                
                # ç¬¬å…­æ­¥ï¼šç­‰å¾…æŸ¥è¯¢ç»“æœåŠ è½½ - ç­‰å¾…åŠ è½½ç»„ä»¶æ¶ˆå¤±
                print("\n6ï¸âƒ£ ç­‰å¾…æŸ¥è¯¢ç»“æœåŠ è½½...")
                await self._wait_for_loading_complete(page)
                
                # ç¬¬ä¸ƒæ­¥ï¼šè·å–æŸ¥è¯¢ç»“æœï¼ˆæ”¯æŒåˆ†é¡µï¼‰
                print("\n7ï¸âƒ£ æ­£åœ¨è·å–æŸ¥è¯¢ç»“æœ...")
                all_result_data = await self._get_all_pages_results(page, applicant_name)
                
                if all_result_data:
                    print("ğŸ‰ æ‰€æœ‰é¡µé¢æŸ¥è¯¢ç»“æœè·å–æˆåŠŸï¼")
                    self._display_results(all_result_data, applicant_name)
                    self._save_results(all_result_data, applicant_name)
                    return all_result_data
                else:
                    print("âŒ æŸ¥è¯¢ç»“æœè·å–å¤±è´¥")
                    return None
                    
            except Exception as e:
                print(f"âŒ è¡¨å•æ“ä½œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                return None
            finally:
                await context.close()
    
    async def _wait_for_login_success(self, page, max_wait_time: int = 60000):
        """
        æ™ºèƒ½ç­‰å¾…ç™»å½•æˆåŠŸ - æ£€æŸ¥"æ¬¢è¿ä½ "ç­‰ç™»å½•æˆåŠŸæ ‡è¯†
        """
        print("ğŸ” æ­£åœ¨æ£€æµ‹ç™»å½•çŠ¶æ€...")
        start_time = asyncio.get_event_loop().time()
        check_count = 0
        
        while (asyncio.get_event_loop().time() - start_time) * 1000 < max_wait_time:
            check_count += 1
            try:
                login_status = await page.evaluate("""
                    () => {
                        // æ£€æŸ¥ç™»å½•æˆåŠŸæ ‡è¯†
                        const pageText = document.body.innerText;
                        const currentUrl = window.location.href;
                        
                        // ç™»å½•æˆåŠŸæ ‡è¯†åˆ—è¡¨
                        const successIndicators = [
                            'æ¬¢è¿ä½ ', 'æ¬¢è¿', 'ç™»å½•æˆåŠŸ', 'å·²ç™»å½•', 'ç”¨æˆ·ä¸­å¿ƒ',
                            'æˆ‘çš„è´¦æˆ·', 'ä¸ªäººä¸­å¿ƒ', 'æŸ¥è¯¢é¡µé¢', 'ä¸“åˆ©æŸ¥è¯¢'
                        ];
                        
                        // æ£€æŸ¥é¡µé¢æ˜¯å¦åŒ…å«ç™»å½•æˆåŠŸæ ‡è¯†
                        for (const indicator of successIndicators) {
                            if (pageText.includes(indicator)) {
                                console.log('âœ… æ£€æµ‹åˆ°ç™»å½•æˆåŠŸæ ‡è¯†: ' + indicator);
                                return {
                                    success: true,
                                    indicator: indicator,
                                    url: currentUrl,
                                    pageTitle: document.title
                                };
                            }
                        }
                        
                        // æ£€æŸ¥URLæ˜¯å¦è·³è½¬åˆ°æŸ¥è¯¢é¡µé¢
                        if (currentUrl.includes('chinesepatent') && !currentUrl.includes('login')) {
                            console.log('âœ… æ£€æµ‹åˆ°å·²è·³è½¬åˆ°æŸ¥è¯¢é¡µé¢');
                            return {
                                success: true,
                                indicator: 'é¡µé¢è·³è½¬',
                                url: currentUrl,
                                pageTitle: document.title
                            };
                        }
                        
                        // æ£€æŸ¥æ˜¯å¦æœ‰ç”³è¯·äººè¾“å…¥æ¡†ï¼ˆç›´æ¥è¿›å…¥æŸ¥è¯¢é¡µé¢ï¼‰
                        const applicantInput = document.querySelector('input[placeholder*="ç”³è¯·äºº"], input[name*="applicant"]');
                        if (applicantInput) {
                            console.log('âœ… æ£€æµ‹åˆ°ç”³è¯·äººè¾“å…¥æ¡†ï¼Œå·²è¿›å…¥æŸ¥è¯¢é¡µé¢');
                            return {
                                success: true,
                                indicator: 'ç”³è¯·äººè¾“å…¥æ¡†',
                                url: currentUrl,
                                pageTitle: document.title
                            };
                        }
                        
                        return {
                            success: false,
                            currentUrl: currentUrl,
                            pageTitle: document.title,
                            hasLoginElements: pageText.includes('ç™»å½•') || pageText.includes('Login')
                        };
                    }
                """)
            except Exception as e:
                # å¦‚æœé¡µé¢æ­£åœ¨å¯¼èˆªï¼Œæ‰§è¡Œä¸Šä¸‹æ–‡å¯èƒ½è¢«é”€æ¯ï¼Œç­‰å¾…é¡µé¢ç¨³å®šåé‡è¯•
                if "Execution context was destroyed" in str(e):
                    print("â³ é¡µé¢æ­£åœ¨å¯¼èˆªï¼Œç­‰å¾…é¡µé¢ç¨³å®š...")
                    await asyncio.sleep(2)
                    continue
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œé‡æ–°æŠ›å‡º
                    raise e
            
            if login_status.get('success'):
                print(f"ğŸ‰ ç™»å½•æˆåŠŸæ£€æµ‹å®Œæˆï¼")
                print(f"  æ ‡è¯†: {login_status.get('indicator')}")
                print(f"  é¡µé¢æ ‡é¢˜: {login_status.get('pageTitle')}")
                print(f"  URL: {login_status.get('url')}")
                return True
            
            # æ¯5æ¬¡æ£€æŸ¥è¾“å‡ºä¸€æ¬¡çŠ¶æ€
            if check_count % 20 == 0:
                print(f"â³ ä»åœ¨ç­‰å¾…ç™»å½•... å·²ç­‰å¾…: {check_count}")
            
            await asyncio.sleep(1)
        
        print(f"â° ç™»å½•ç­‰å¾…è¶…æ—¶ï¼Œå…±æ£€æŸ¥ {check_count} æ¬¡")
        return False
    
    async def _wait_for_applicant_input(self, page, max_wait_time: int = 60000):
        """
        ç­‰å¾…ç”³è¯·äººè¾“å…¥æ¡†å‡ºç°
        """
        start_time = asyncio.get_event_loop().time()
        
        while (asyncio.get_event_loop().time() - start_time) * 1000 < max_wait_time:
            applicant_input = await page.evaluate("""
                () => {
                    // XPath å®šä½å‡½æ•°
                    function findByXPath(xpath) {
                        try {
                            const result = document.evaluate(xpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null);
                            return result.singleNodeValue;
                        } catch (e) {
                            return null;
                        }
                    }
                    
                    // å¤šç­–ç•¥å®šä½ç”³è¯·äººè¾“å…¥æ¡†
                    const xpaths = [
                        "//div[normalize-space(text())='ç”³è¯·äººï¼š']/following-sibling::label[contains(@class, 'q-field')]//input[@type='text']",
                        "//div[contains(@class, 'q-item__label') and normalize-space(text())='ç”³è¯·äººï¼š']/following-sibling::label//input",
                        "//label[preceding-sibling::div[normalize-space(text())='ç”³è¯·äººï¼š']]//input[@type='text']",
                        "//div[contains(@class, 'row') and .//div[normalize-space(text())='ç”³è¯·äººï¼š']]//input[@type='text']"
                    ];
                    
                    for (let xpath of xpaths) {
                        const input = findByXPath(xpath);
                        if (input) {
                            console.log('âœ… ä½¿ç”¨ XPath æ‰¾åˆ°ç”³è¯·äººè¾“å…¥æ¡†:', xpath);
                            return input;
                        }
                    }
                    return null;
                }
            """)
            
            if applicant_input:
                return applicant_input
            
            await asyncio.sleep(0.5)
        
        return None
    
    async def _click_search_button(self, page):
        """
        ç‚¹å‡»æŸ¥è¯¢æŒ‰é’® - ç²¾ç¡®å®šä½è¡¨å•åŒºåŸŸå†…çš„æŸ¥è¯¢æŒ‰é’®
        """
        return await page.evaluate("""
            () => {
                // XPath å®šä½å‡½æ•°
                function findByXPath(xpath) {
                    try {
                        const result = document.evaluate(xpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null);
                        return result.singleNodeValue;
                    } catch (e) {
                        return null;
                    }
                }
                
                // å¤šç­–ç•¥ç²¾ç¡®æŸ¥æ‰¾è¡¨å•åŒºåŸŸå†…çš„æŸ¥è¯¢æŒ‰é’®
                const searchButtonStrategies = [
                    // ç­–ç•¥1: åœ¨è¡¨å•åŒºåŸŸå†…æŸ¥æ‰¾åŒ…å«"æŸ¥è¯¢"æ–‡æœ¬çš„æŒ‰é’®
                    "//form//button[.//span[normalize-space(text())='æŸ¥è¯¢']]",
                    
                    // ç­–ç•¥2: åœ¨ç”³è¯·äººè¾“å…¥æ¡†é™„è¿‘çš„æŸ¥è¯¢æŒ‰é’®
                    "//div[contains(@class, 'row') and .//div[normalize-space(text())='ç”³è¯·äººï¼š']]/following-sibling::div//button[.//span[normalize-space(text())='æŸ¥è¯¢']]",
                    
                    // ç­–ç•¥3: åœ¨æŸ¥è¯¢æ¡ä»¶åŒºåŸŸå†…çš„æŸ¥è¯¢æŒ‰é’®
                    "//div[contains(@class, 'search-condition')]//button[.//span[normalize-space(text())='æŸ¥è¯¢']]",
                    
                    // ç­–ç•¥4: ä½¿ç”¨CSSé€‰æ‹©å™¨æŸ¥æ‰¾ç‰¹å®šç±»åçš„æŸ¥è¯¢æŒ‰é’®
                    "button.q-btn--standard:has(span:contains('æŸ¥è¯¢'))",
                    
                    // ç­–ç•¥5: æŸ¥æ‰¾åŒ…å«æŸ¥è¯¢å›¾æ ‡çš„æŒ‰é’®
                    "//button[contains(@class, 'q-btn') and .//span[normalize-space(text())='æŸ¥è¯¢']]",
                    
                    // ç­–ç•¥6: åœ¨ç”³è¯·äººè¾“å…¥æ¡†åŒä¸€è¡Œçš„æŸ¥è¯¢æŒ‰é’®
                    "//div[.//div[normalize-space(text())='ç”³è¯·äººï¼š']]//button[.//span[normalize-space(text())='æŸ¥è¯¢']]"
                ];
                
                console.log("ğŸ” å¼€å§‹æŸ¥æ‰¾æŸ¥è¯¢æŒ‰é’®...");
                
                for (let i = 0; i < searchButtonStrategies.length; i++) {
                    const strategy = searchButtonStrategies[i];
                    let button = null;
                    
                    if (strategy.startsWith('//')) {
                        // XPath å®šä½
                        button = findByXPath(strategy);
                    } else {
                        // CSS é€‰æ‹©å™¨å®šä½
                        button = document.querySelector(strategy);
                    }
                    
                    if (button) {
                        console.log(`âœ… ä½¿ç”¨ç­–ç•¥ ${i+1} æ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®:`, strategy);
                        console.log('ğŸ” æŒ‰é’®ä¿¡æ¯:', {
                            text: button.textContent,
                            className: button.className,
                            tagName: button.tagName,
                            parentHTML: button.parentElement ? button.parentElement.outerHTML.substring(0, 200) : 'no parent'
                        });
                        
                        // ç‚¹å‡»æŒ‰é’®
                        button.click();
                        console.log('âœ… æŸ¥è¯¢æŒ‰é’®å·²ç‚¹å‡»');
                        return {
                            success: true,
                            strategy: strategy,
                            buttonInfo: {
                                text: button.textContent,
                                className: button.className
                            }
                        };
                    } else {
                        console.log(`âŒ ç­–ç•¥ ${i+1} æœªæ‰¾åˆ°æŒ‰é’®:`, strategy);
                    }
                }
                
                // å¦‚æœæ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰åŒ…å«"æŸ¥è¯¢"çš„æŒ‰é’®å¹¶è¾“å‡ºè°ƒè¯•ä¿¡æ¯
                console.log('ğŸ” å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾æ‰€æœ‰åŒ…å«"æŸ¥è¯¢"çš„æŒ‰é’®');
                const allButtons = document.querySelectorAll('button');
                const queryButtons = Array.from(allButtons).filter(btn => 
                    btn.textContent.includes('æŸ¥è¯¢')
                );
                
                console.log(`ğŸ“Š æ‰¾åˆ° ${queryButtons.length} ä¸ªåŒ…å«"æŸ¥è¯¢"çš„æŒ‰é’®:`);
                queryButtons.forEach((btn, index) => {
                    console.log(`  æŒ‰é’® ${index+1}:`, {
                        text: btn.textContent.trim(),
                        className: btn.className,
                        parentText: btn.parentElement ? btn.parentElement.textContent.substring(0, 100) : 'no parent'
                    });
                });
                
                return {
                    success: false,
                    message: 'æœªæ‰¾åˆ°åˆé€‚çš„æŸ¥è¯¢æŒ‰é’®',
                    foundButtons: queryButtons.length
                };
            }
        """)
    
    async def _wait_for_loading_complete(self, page, max_wait_time: int = 30000):
        """
        ç­‰å¾…åŠ è½½ç»„ä»¶æ¶ˆå¤± - æ£€æŸ¥ class=q-loading çš„ç»„ä»¶æ˜¯å¦æ¶ˆå¤±
        """
        print("â³ ç­‰å¾…åŠ è½½ç»„ä»¶æ¶ˆå¤±...")
        start_time = asyncio.get_event_loop().time()
        
        while (asyncio.get_event_loop().time() - start_time) * 1000 < max_wait_time:
            loading_complete = await page.evaluate("""
                () => {
                    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨ class=q-loading çš„ç»„ä»¶
                    const loadingElements = document.querySelectorAll('.q-loading');
                    const hasLoading = loadingElements.length > 0;
                    
                    if (!hasLoading) {
                        console.log('âœ… åŠ è½½ç»„ä»¶å·²æ¶ˆå¤±ï¼ŒæŸ¥è¯¢ç»“æœåŠ è½½å®Œæˆ');
                        return true;
                    } else {
                        console.log('â³ ä»åœ¨åŠ è½½ä¸­ï¼Œæ‰¾åˆ° ' + loadingElements.length + ' ä¸ªåŠ è½½ç»„ä»¶');
                        // è¾“å‡ºåŠ è½½ç»„ä»¶çš„è¯¦ç»†ä¿¡æ¯ç”¨äºè°ƒè¯•
                        loadingElements.forEach((el, index) => {
                            console.log(`  åŠ è½½ç»„ä»¶ ${index+1}:`, {
                                className: el.className,
                                parentText: el.parentElement ? el.parentElement.textContent.substring(0, 100) : 'no parent',
                                visible: el.offsetParent !== null
                            });
                        });
                        return false;
                    }
                }
            """)
            
            if loading_complete:
                print("âœ… æŸ¥è¯¢ç»“æœåŠ è½½å®Œæˆ")
                return True
            
            await asyncio.sleep(0.5)
        
        print("âš ï¸ ç­‰å¾…åŠ è½½ç»„ä»¶è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ...")
        return False
    
    async def _get_pagination_info(self, page):
        """
        è·å–åˆ†é¡µä¿¡æ¯
        """
        return await page.evaluate("""
            () => {
                // è·å–åˆ†é¡µä¿¡æ¯
                const paginationInfo = {
                    totalResults: document.querySelector('.total strong') ? document.querySelector('.total strong').textContent : '0',
                    currentPage: 1,
                    totalPages: 1,
                    hasNextPage: false,
                    nextPageButton: null
                };
                
                // è·å–åˆ†é¡µæŒ‰é’®
                const paginationContainer = document.querySelector('.q-pagination');
                if (paginationContainer) {
                    // è·å–å½“å‰é¡µç 
                    const activeButton = paginationContainer.querySelector('.q-btn--standard');
                    if (activeButton) {
                        const pageText = activeButton.textContent.trim();
                        if (pageText && !isNaN(parseInt(pageText))) {
                            paginationInfo.currentPage = parseInt(pageText);
                        }
                    }
                    
                    // è·å–æ€»é¡µæ•° - æŸ¥æ‰¾æœ€åä¸€ä¸ªé¡µç æŒ‰é’®
                    const pageButtons = paginationContainer.querySelectorAll('.q-btn:not(.q-btn--disabled)');
                    let lastPage = 1;
                    pageButtons.forEach(btn => {
                        const text = btn.textContent.trim();
                        if (text && !isNaN(parseInt(text))) {
                            const pageNum = parseInt(text);
                            if (pageNum > lastPage) {
                                lastPage = pageNum;
                            }
                        }
                    });
                    paginationInfo.totalPages = lastPage;
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µæŒ‰é’® - ä¿®å¤é€‰æ‹©å™¨
                    const nextButtons = Array.from(paginationContainer.querySelectorAll('.q-btn:not(.q-btn--disabled)'));
                    const nextButton = nextButtons.find(btn => {
                        const icons = btn.querySelectorAll('.material-icons');
                        return Array.from(icons).some(icon => 
                            icon.textContent.includes('keyboard_arrow_right')
                        );
                    });
                    
                    if (nextButton) {
                        paginationInfo.hasNextPage = true;
                        paginationInfo.nextPageButton = nextButton;
                    }
                }
                
                return paginationInfo;
            }
        """)
    
    async def _click_next_page(self, page):
        """
        ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®
        """
        return await page.evaluate("""
            () => {
                // æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’®
                const paginationContainer = document.querySelector('.q-pagination');
                if (!paginationContainer) {
                    return { success: false, message: 'æœªæ‰¾åˆ°åˆ†é¡µå®¹å™¨' };
                }
                
                // æŸ¥æ‰¾åŒ…å«å³ç®­å¤´å›¾æ ‡çš„æŒ‰é’®
                const nextButtons = Array.from(paginationContainer.querySelectorAll('.q-btn'));
                const nextButton = nextButtons.find(btn => {
                    const icons = btn.querySelectorAll('.material-icons');
                    return Array.from(icons).some(icon => 
                        icon.textContent.includes('keyboard_arrow_right')
                    );
                });
                
                if (nextButton && !nextButton.disabled) {
                    console.log('âœ… æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œæ­£åœ¨ç‚¹å‡»...');
                    nextButton.click();
                    return { 
                        success: true, 
                        message: 'ä¸‹ä¸€é¡µæŒ‰é’®å·²ç‚¹å‡»',
                        buttonInfo: {
                            text: nextButton.textContent,
                            className: nextButton.className
                        }
                    };
                } else {
                    console.log('âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®');
                    return { 
                        success: false, 
                        message: 'æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®',
                        nextButtonExists: !!nextButton,
                        nextButtonDisabled: nextButton ? nextButton.disabled : false
                    };
                }
            }
        """)
    
    async def _get_all_pages_results(self, page, applicant_name: str):
        """
        è·å–æ‰€æœ‰é¡µé¢çš„æŸ¥è¯¢ç»“æœ
        """
        print("ğŸ“„ å¼€å§‹è·å–æ‰€æœ‰é¡µé¢æ•°æ®...")
        
        all_results = {
            'resultInfo': {},
            'tableData': [],
            'tableInfoData': [],
            'fullPageHTML': '',
            'pageTitle': '',
            'url': '',
            'paginationStats': {
                'totalPages': 0,
                'currentPage': 0,
                'totalResults': 0,
                'pagesCollected': 0
            }
        }
        
        current_page = 1
        max_pages = 100  # å®‰å…¨é™åˆ¶ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        
        while current_page <= max_pages:
            print(f"\nğŸ“– æ­£åœ¨è·å–ç¬¬ {current_page} é¡µæ•°æ®...")
            
            # è·å–å½“å‰é¡µé¢ç»“æœ
            page_result = await self._get_query_results(page, applicant_name)
            
            if not page_result:
                print(f"âŒ ç¬¬ {current_page} é¡µæ•°æ®è·å–å¤±è´¥")
                break
            
            # å¦‚æœæ˜¯ç¬¬ä¸€é¡µï¼Œåˆå§‹åŒ–åŸºç¡€ä¿¡æ¯
            if current_page == 1:
                all_results['resultInfo'] = page_result.get('resultInfo', {})
                all_results['fullPageHTML'] = page_result.get('fullPageHTML', '')
                all_results['pageTitle'] = page_result.get('pageTitle', '')
                all_results['url'] = page_result.get('url', '')
                
                # è·å–åˆ†é¡µç»Ÿè®¡ä¿¡æ¯
                pagination_info = await self._get_pagination_info(page)
                all_results['paginationStats']['totalPages'] = pagination_info.get('totalPages', 1)
                all_results['paginationStats']['totalResults'] = pagination_info.get('totalResults', '0')
            
            # åˆå¹¶æ•°æ®
            if 'tableData' in page_result:
                all_results['tableData'].extend(page_result['tableData'])
            
            if 'tableInfoData' in page_result:
                all_results['tableInfoData'].extend(page_result['tableInfoData'])
            
            all_results['paginationStats']['pagesCollected'] = current_page
            all_results['paginationStats']['currentPage'] = current_page
            
            print(f"âœ… ç¬¬ {current_page} é¡µæ•°æ®è·å–æˆåŠŸ")
            print(f"  è¡¨æ ¼æ•°æ®: {len(page_result.get('tableData', []))} è¡Œ")
            print(f"  table_info æ•°æ®: {len(page_result.get('tableInfoData', []))} æ¡")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            pagination_info = await self._get_pagination_info(page)
            has_next_page = pagination_info.get('hasNextPage', False)
            total_pages = pagination_info.get('totalPages', 1)
            
            print(f"ğŸ“Š åˆ†é¡µä¿¡æ¯: å½“å‰é¡µ {current_page}/{total_pages}, æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ: {has_next_page}")
            
            if not has_next_page or current_page >= total_pages:
                print("ğŸ¯ å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œåˆ†é¡µæ”¶é›†å®Œæˆ")
                break
            
            # ç‚¹å‡»ä¸‹ä¸€é¡µ
            print("ğŸ”„ æ­£åœ¨ç‚¹å‡»ä¸‹ä¸€é¡µ...")
            next_result = await self._click_next_page(page)
            
            if not next_result.get('success'):
                print(f"âŒ ç‚¹å‡»ä¸‹ä¸€é¡µå¤±è´¥: {next_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                break
            
            # ç­‰å¾…ä¸‹ä¸€é¡µåŠ è½½
            print("â³ ç­‰å¾…ä¸‹ä¸€é¡µæ•°æ®åŠ è½½...")
            ret = await self._wait_for_loading_complete(page)
            if not ret:
                return None
            
            # ç­‰å¾…é¡µé¢ç¨³å®š
            await asyncio.sleep(2)
            
            current_page += 1
        
        # æ•°æ®å»é‡ï¼ˆåŸºäºç”³è¯·å·ï¼‰
        if all_results['tableInfoData']:
            unique_table_info_data = self._deduplicate_table_info(all_results['tableInfoData'])
            all_results['tableInfoData'] = unique_table_info_data
        
        print(f"\nğŸ“Š åˆ†é¡µæ”¶é›†å®Œæˆç»Ÿè®¡:")
        print(f"  æ€»é¡µæ•°: {all_results['paginationStats']['totalPages']}")
        print(f"  å·²æ”¶é›†é¡µæ•°: {all_results['paginationStats']['pagesCollected']}")
        print(f"  æ€»ç»“æœæ•°: {all_results['paginationStats']['totalResults']}")
        print(f"  è¡¨æ ¼æ•°æ®è¡Œæ•°: {len(all_results['tableData'])}")
        print(f"  table_info æ•°æ®æ¡æ•°: {len(all_results['tableInfoData'])}")
        
        return all_results
    
    def _deduplicate_table_info(self, table_info_data):
        """
        åŸºäºç”³è¯·å·å»é‡ table_info æ•°æ®
        """
        seen_app_numbers = set()
        unique_data = []
        
        for item in table_info_data:
            app_number = None
            text = item.get('text', '')
            
            # ä»æ–‡æœ¬ä¸­æå–ç”³è¯·å·
            app_number_match = re.search(r'ç”³è¯·å·/ä¸“åˆ©å·ï¼š\s*([^\s]+)', text)
            if app_number_match:
                app_number = app_number_match.group(1).strip()
            
            if app_number and app_number not in seen_app_numbers:
                seen_app_numbers.add(app_number)
                unique_data.append(item)
            elif not app_number:
                # å¦‚æœæ²¡æœ‰ç”³è¯·å·ï¼Œç›´æ¥ä¿ç•™
                unique_data.append(item)
        
        print(f"ğŸ” æ•°æ®å»é‡: {len(table_info_data)} -> {len(unique_data)} æ¡")
        return unique_data
    
    async def _get_query_results(self, page, applicant_name: str):
        """
        è·å–æŸ¥è¯¢ç»“æœ
        """
        return await page.evaluate("""
            () => {
                // è·å–æŸ¥è¯¢ç»“æœä¿¡æ¯
                const resultInfo = {
                    totalResults: document.querySelector('.total strong') ? document.querySelector('.total strong').textContent : '0',
                    tableContent: document.querySelector('.tableList') ? document.querySelector('.tableList').innerHTML : '',
                    pageInfo: document.querySelector('.q-pagination') ? document.querySelector('.q-pagination').innerHTML : ''
                };
                
                // è·å–æ‰€æœ‰å¯è§çš„è¡¨æ ¼æ•°æ®
                const tableRows = document.querySelectorAll('.tableList tr, .tableList .row');
                const tableData = Array.from(tableRows).map(row => ({
                    html: row.outerHTML,
                    text: row.textContent.trim()
                }));
                
                // è·å–æ‰€æœ‰ table_info æ•°æ®
                const tableInfoElements = document.querySelectorAll('.table_info');
                const tableInfoData = Array.from(tableInfoElements).map(info => ({
                    html: info.outerHTML,
                    text: info.textContent.trim()
                }));
                
                return {
                    resultInfo: resultInfo,
                    tableData: tableData,
                    tableInfoData: tableInfoData,
                    fullPageHTML: document.documentElement.outerHTML,
                    pageTitle: document.title,
                    url: window.location.href
                };
            }
        """)
    
    def _display_results(self, result_data, applicant_name: str):
        """æ˜¾ç¤ºè¡¨å•æ“ä½œç»“æœ"""
        print("\n" + "=" * 50)
        print("ğŸ“Š è¡¨å•æ“ä½œç»“æœæ‘˜è¦")
        print("=" * 50)
        print(f"ğŸ”— æœ€ç»ˆURL: {result_data.get('url', 'æœªçŸ¥')}")
        print(f"ğŸ‘¤ ç”³è¯·äºº: {applicant_name}")
        
        if 'resultInfo' in result_data:
            print(f"ğŸ“ˆ æŸ¥è¯¢ç»“æœæ•°é‡: {result_data['resultInfo'].get('totalResults', '0')}")
        
        if 'tableData' in result_data and result_data['tableData']:
            print(f"ğŸ“‹ è¡¨æ ¼æ•°æ®è¡Œæ•°: {len(result_data['tableData'])}")
            # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®é¢„è§ˆ
            for i, row in enumerate(result_data['tableData'][:3]):
                print(f"  è¡Œ {i+1}: {row['text'][:100]}...")
    
    def _extract_table_info(self, result_data):
        """
        ä»æŸ¥è¯¢ç»“æœä¸­æå– table_info ç»“æ„åŒ–æ•°æ®
        """
        table_info_list = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ tableInfoData å­—æ®µ
        if 'tableInfoData' in result_data and result_data['tableInfoData']:
            for table_info in result_data['tableInfoData']:
                info_text = table_info.get('text', '')
                info_html = table_info.get('html', '')
                
                patent_data = self._parse_patent_info(info_html)
                patent_data['raw_text'] = info_text
                table_info_list.append(patent_data)
        
        # å¦‚æœæ²¡æœ‰æ–°çš„ tableInfoDataï¼Œå°è¯•ä» tableContent ä¸­æå–
        elif 'resultInfo' in result_data and 'tableContent' in result_data['resultInfo']:
            table_content = result_data['resultInfo']['tableContent']
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä» tableContent ä¸­æå– table_info å—
            table_info_pattern = r'<div[^>]*class="table_info"[^>]*>(.*?)</div>'
            table_info_matches = re.findall(table_info_pattern, table_content, re.DOTALL)
            
            for table_info_html in table_info_matches:
                # æå–çº¯æ–‡æœ¬å†…å®¹
                info_text = re.sub(r'<[^>]+>', ' ', table_info_html)
                info_text = re.sub(r'\s+', ' ', info_text).strip()
                
                patent_data = self._parse_patent_info(info_text)
                patent_data['raw_text'] = info_text
                table_info_list.append(patent_data)
        
        return table_info_list
    
    def _parse_patent_info(self, info_html):
        """è§£æä¸“åˆ©ä¿¡æ¯HTML"""
        patent_data = {}
        
        # å¦‚æœä¼ å…¥çš„æ˜¯çº¯æ–‡æœ¬ï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„çº¯æ–‡æœ¬è§£æ
        if not info_html.startswith('<'):
            return self._parse_patent_info_text(info_html)
        
        # å¯¹äºHTMLæ ¼å¼ï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´ç²¾ç¡®çš„HTMLæ ‡ç­¾ç»“æ„æ¥æå–å­—æ®µ
        # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼Œèƒ½å¤Ÿæ­£ç¡®å¤„ç†åµŒå¥—æ ‡ç­¾å’Œå­—æ®µè¾¹ç•Œ
        
        # æå–ç”³è¯·å·/ä¸“åˆ©å· - ç²¾ç¡®åŒ¹é… hover_active ç±»
        app_number_match = re.search(r'ç”³è¯·å·/ä¸“åˆ©å·ï¼š\s*</span>\s*<span[^>]*class="hover_active"[^>]*>([^<]*)</span>', info_html)
        if app_number_match:
            patent_data['application_number'] = app_number_match.group(1).strip()
        
        # æå–å‘æ˜åç§° - ç²¾ç¡®åŒ¹é…åµŒå¥—çš„ span
        invention_name_match = re.search(r'å‘æ˜åç§°ï¼š<span[^>]*>([^<]*)</span>', info_html)
        if invention_name_match:
            patent_data['invention_name'] = invention_name_match.group(1).strip()
        
        # æå–ç”³è¯·äºº - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼ï¼ŒåŒ¹é…åˆ°ä¸‹ä¸€ä¸ª span æ ‡ç­¾æˆ–è¡Œç»“æŸ
        applicant_match = re.search(r'ç”³è¯·äººï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if applicant_match:
            applicant_text = applicant_match.group(1).strip()
            # æ¸…ç†å¯èƒ½åŒ…å«çš„HTMLæ ‡ç­¾
            applicant_text = re.sub(r'<[^>]+>', '', applicant_text).strip()
            patent_data['applicant'] = applicant_text
        
        # æå–ä¸“åˆ©ç±»å‹ - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        patent_type_match = re.search(r'ä¸“åˆ©ç±»å‹ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if patent_type_match:
            patent_type_text = patent_type_match.group(1).strip()
            patent_type_text = re.sub(r'<[^>]+>', '', patent_type_text).strip()
            patent_data['patent_type'] = patent_type_text
        
        # æå–ç”³è¯·æ—¥ - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        application_date_match = re.search(r'ç”³è¯·æ—¥ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if application_date_match:
            application_date_text = application_date_match.group(1).strip()
            application_date_text = re.sub(r'<[^>]+>', '', application_date_text).strip()
            patent_data['application_date'] = application_date_text
        
        # æå–å‘æ˜ä¸“åˆ©ç”³è¯·å…¬å¸ƒå· - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        publication_number_match = re.search(r'å‘æ˜ä¸“åˆ©ç”³è¯·å…¬å¸ƒå·ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if publication_number_match:
            publication_number_text = publication_number_match.group(1).strip()
            publication_number_text = re.sub(r'<[^>]+>', '', publication_number_text).strip()
            patent_data['publication_number'] = publication_number_text
        
        # æå–æˆæƒå…¬å‘Šå· - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        grant_number_match = re.search(r'æˆæƒå…¬å‘Šå·ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if grant_number_match:
            grant_number_text = grant_number_match.group(1).strip()
            grant_number_text = re.sub(r'<[^>]+>', '', grant_number_text).strip()
            patent_data['grant_number'] = grant_number_text
        
        # æå–æ¡ˆä»¶çŠ¶æ€ - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        case_status_match = re.search(r'æ¡ˆä»¶çŠ¶æ€ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if case_status_match:
            case_status_text = case_status_match.group(1).strip()
            case_status_text = re.sub(r'<[^>]+>', '', case_status_text).strip()
            patent_data['case_status'] = case_status_text
        
        # æå–æˆæƒå…¬å‘Šæ—¥ - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        grant_date_match = re.search(r'æˆæƒå…¬å‘Šæ—¥ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if grant_date_match:
            grant_date_text = grant_date_match.group(1).strip()
            grant_date_text = re.sub(r'<[^>]+>', '', grant_date_text).strip()
            patent_data['grant_date'] = grant_date_text
        
        # æå–ä¸»åˆ†ç±»å· - ä½¿ç”¨æ›´é€šç”¨çš„åŒ¹é…æ¨¡å¼
        main_class_match = re.search(r'ä¸»åˆ†ç±»å·ï¼š([^<]*)(?=<span|</span>|$)', info_html)
        if main_class_match:
            main_class_text = main_class_match.group(1).strip()
            main_class_text = re.sub(r'<[^>]+>', '', main_class_text).strip()
            patent_data['main_classification'] = main_class_text
        
        # å¦‚æœHTMLè§£æå¤±è´¥ï¼Œå›é€€åˆ°çº¯æ–‡æœ¬è§£æ
        if not patent_data:
            clean_text = re.sub(r'<[^>]+>', ' ', info_html)
            clean_text = re.sub(r'\s+', ' ', clean_text).strip()
            patent_data = self._parse_patent_info_text(clean_text)
        
        return patent_data
    
    def _parse_patent_info_text(self, info_text):
        """è§£æçº¯æ–‡æœ¬æ ¼å¼çš„ä¸“åˆ©ä¿¡æ¯ï¼ˆå‘åå…¼å®¹ï¼‰"""
        patent_data = {}
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„çº¯æ–‡æœ¬è§£æï¼Œé¿å…å­—æ®µè¾¹ç•Œæ··æ·†
        # æå–ç”³è¯·å·/ä¸“åˆ©å·
        app_number_match = re.search(r'ç”³è¯·å·/ä¸“åˆ©å·ï¼š\s*([^\s]+)', info_text)
        if app_number_match:
            patent_data['application_number'] = app_number_match.group(1).strip()
        
        # æå–å‘æ˜åç§° - ä½¿ç”¨æ›´ç²¾ç¡®çš„è¾¹ç•Œ
        invention_name_match = re.search(r'å‘æ˜åç§°ï¼š([^ç”³]+?)(?=\s*ç”³è¯·äººï¼š|\s*ä¸“åˆ©ç±»å‹ï¼š|$)', info_text)
        if invention_name_match:
            patent_data['invention_name'] = invention_name_match.group(1).strip()
        
        # æå–ç”³è¯·äºº - ä½¿ç”¨æ›´ç²¾ç¡®çš„è¾¹ç•Œ
        applicant_match = re.search(r'ç”³è¯·äººï¼š([^ä¸“]+?)(?=\s*ä¸“åˆ©ç±»å‹ï¼š|\s*ç”³è¯·æ—¥ï¼š|$)', info_text)
        if applicant_match:
            patent_data['applicant'] = applicant_match.group(1).strip()
        
        # æå–ä¸“åˆ©ç±»å‹ - ä½¿ç”¨æ›´ç²¾ç¡®çš„è¾¹ç•Œ
        patent_type_match = re.search(r'ä¸“åˆ©ç±»å‹ï¼š([^ç”³]+?)(?=\s*ç”³è¯·æ—¥ï¼š|\s*å‘æ˜ä¸“åˆ©ç”³è¯·å…¬å¸ƒå·ï¼š|$)', info_text)
        if patent_type_match:
            patent_data['patent_type'] = patent_type_match.group(1).strip()
        
        # æå–ç”³è¯·æ—¥
        application_date_match = re.search(r'ç”³è¯·æ—¥ï¼š([^\s]+)', info_text)
        if application_date_match:
            patent_data['application_date'] = application_date_match.group(1).strip()
        
        # æå–å‘æ˜ä¸“åˆ©ç”³è¯·å…¬å¸ƒå·
        publication_number_match = re.search(r'å‘æ˜ä¸“åˆ©ç”³è¯·å…¬å¸ƒå·ï¼š([^\s]+)', info_text)
        if publication_number_match:
            patent_data['publication_number'] = publication_number_match.group(1).strip()
        
        # æå–æˆæƒå…¬å‘Šå·
        grant_number_match = re.search(r'æˆæƒå…¬å‘Šå·ï¼š([^\s]+)', info_text)
        if grant_number_match:
            patent_data['grant_number'] = grant_number_match.group(1).strip()
        
        # æå–æ¡ˆä»¶çŠ¶æ€ - ä½¿ç”¨æ›´ç²¾ç¡®çš„è¾¹ç•Œ
        case_status_match = re.search(r'æ¡ˆä»¶çŠ¶æ€ï¼š([^æˆ]+?)(?=\s*æˆæƒå…¬å‘Šæ—¥ï¼š|\s*ä¸»åˆ†ç±»å·ï¼š|$)', info_text)
        if case_status_match:
            patent_data['case_status'] = case_status_match.group(1).strip()
        
        # æå–æˆæƒå…¬å‘Šæ—¥
        grant_date_match = re.search(r'æˆæƒå…¬å‘Šæ—¥ï¼š([^\s]+)', info_text)
        if grant_date_match:
            patent_data['grant_date'] = grant_date_match.group(1).strip()
        
        # æå–ä¸»åˆ†ç±»å·
        main_class_match = re.search(r'ä¸»åˆ†ç±»å·ï¼š([^\s]+)', info_text)
        if main_class_match:
            patent_data['main_classification'] = main_class_match.group(1).strip()
        
        return patent_data
    
    def export_table_info(self, result_data, applicant_name: str, export_format: str = "csv"):
        """
        å¯¼å‡º table_info æ•°æ®åˆ°æŒ‡å®šæ ¼å¼
        
        Args:
            result_data: æŸ¥è¯¢ç»“æœæ•°æ®
            applicant_name: ç”³è¯·äººåç§°
            export_format: å¯¼å‡ºæ ¼å¼ï¼Œæ”¯æŒ 'csv', 'json', 'excel'
        """
        import time
        timestamp = int(time.time())
        
        # æå– table_info æ•°æ®
        table_info_data = self._extract_table_info(result_data)
        
        if not table_info_data:
            print("âŒ æœªæ‰¾åˆ° table_info æ•°æ®")
            return
        
        print(f"ğŸ“Š æå–åˆ° {len(table_info_data)} æ¡ table_info æ•°æ®")
        
        try:
            if export_format == "csv":
                filename = f"table_info_{applicant_name}_{timestamp}.csv"
                self._export_to_csv(table_info_data, filename)
            elif export_format == "json":
                filename = f"table_info_{applicant_name}_{timestamp}.json"
                self._export_to_json(table_info_data, filename)
            elif export_format == "excel":
                filename = f"table_info_{applicant_name}_{timestamp}.xlsx"
                self._export_to_excel(table_info_data, filename)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")
                return
            
            print(f"ğŸ’¾ table_info æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡º table_info æ•°æ®å¤±è´¥: {e}")
    
    def _export_to_csv(self, table_info_data, filename):
        """å¯¼å‡ºä¸º CSV æ ¼å¼"""
        if not table_info_data:
            return
        
        # å®šä¹‰å›ºå®šçš„å­—æ®µé¡ºåºå’Œä¸­æ–‡åˆ—åæ˜ å°„
        field_mapping = {
            'sequence': 'åºå·',
            'applicant': 'ä¸“åˆ©æƒäºº',
            'application_date': 'ç”³è¯·æ—¥',
            'invention_name': 'ä¸“åˆ©åç§°',
            'application_number': 'ä¸“åˆ©å·',
            'grant_date': 'æˆæƒå…¬å‘Šæ—¥',
            'patent_type': 'ä¸“åˆ©ç±»å‹',
            'publication_number': 'å‘æ˜ä¸“åˆ©ç”³è¯·å…¬å¸ƒå·',
            'grant_number': 'æˆæƒå…¬å‘Šå·',
            'case_status': 'æ¡ˆä»¶çŠ¶æ€',
            'main_classification': 'ä¸»åˆ†ç±»å·'
        }
        
        # è·å–æ‰€æœ‰å¯èƒ½çš„å­—æ®µï¼ˆæ’é™¤ raw_textï¼‰
        all_fields = set()
        for item in table_info_data:
            all_fields.update(item.keys())
        all_fields.discard('raw_text')
        
        # ç¡®ä¿åŒ…å«åºå·å­—æ®µ
        all_fields.add('sequence')
        
        # æŒ‰ç…§æŒ‡å®šé¡ºåºæ’åˆ—å­—æ®µï¼ŒæœªæŒ‡å®šçš„å­—æ®µæ”¾åœ¨æœ€å
        ordered_fields = []
        for field in field_mapping.keys():
            if field in all_fields:
                ordered_fields.append(field)
        
        # æ·»åŠ å…¶ä»–æœªæŒ‡å®šçš„å­—æ®µ
        for field in sorted(all_fields):
            if field not in ordered_fields:
                ordered_fields.append(field)
        
        # å‡†å¤‡å†™å…¥æ•°æ®
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            # ä½¿ç”¨ä¸­æ–‡åˆ—å
            chinese_headers = [field_mapping.get(field, field) for field in ordered_fields]
            writer = csv.DictWriter(csvfile, fieldnames=ordered_fields)
            
            # å†™å…¥ä¸­æ–‡è¡¨å¤´
            writer.writerow(dict(zip(ordered_fields, chinese_headers)))
            
            # å†™å…¥æ•°æ®è¡Œ
            for i, item in enumerate(table_info_data):
                # è¿‡æ»¤æ‰ raw_text å­—æ®µ
                filtered_item = {k: v for k, v in item.items() if k != 'raw_text'}
                # æ·»åŠ åºå·
                filtered_item['sequence'] = i + 1
                writer.writerow(filtered_item)
    
    def _export_to_json(self, table_info_data, filename):
        """å¯¼å‡ºä¸º JSON æ ¼å¼"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(table_info_data, f, ensure_ascii=False, indent=2)
    
    def _export_to_excel(self, table_info_data, filename):
        """å¯¼å‡ºä¸º Excel æ ¼å¼"""
        try:
            # åˆ›å»º DataFrame
            df_data = []
            for item in table_info_data:
                # è¿‡æ»¤æ‰ raw_text å­—æ®µ
                filtered_item = {k: v for k, v in item.items() if k != 'raw_text'}
                df_data.append(filtered_item)
            
            df = pd.DataFrame(df_data)
            df.to_excel(filename, index=False, engine='openpyxl')
        except ImportError:
            print("âŒ æœªå®‰è£… pandas åº“ï¼Œæ— æ³•å¯¼å‡º Excel æ ¼å¼")
            print("ğŸ’¡ è¯·è¿è¡Œ: pip install pandas openpyxl")
    
    def _save_results(self, result_data, applicant_name: str):
        """ä¿å­˜è¡¨å•æ“ä½œç»“æœåˆ°æ–‡ä»¶"""
        import time
        timestamp = int(time.time())
        filename = f"playwright_result_{applicant_name}_{timestamp}.json"
        
        try:
            result_data["applicant_name"] = applicant_name
            result_data["timestamp"] = timestamp
            
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ è¡¨å•æ“ä½œç»“æœå·²ä¿å­˜åˆ°: {filename}")
            
            # åŒæ—¶ä¿å­˜ä¸ºå¯è¯»çš„æ–‡æœ¬æ–‡ä»¶
            text_filename = f"playwright_result_{applicant_name}_{timestamp}.txt"
            with open(text_filename, "w", encoding="utf-8") as f:
                f.write(f"ç”³è¯·äºº: {applicant_name}\n")
                f.write(f"æŸ¥è¯¢æ—¶é—´: {timestamp}\n")
                f.write(f"URL: {result_data.get('url', 'æœªçŸ¥')}\n")
                f.write("=" * 60 + "\n\n")
                
                if 'resultInfo' in result_data:
                    f.write(f"æŸ¥è¯¢ç»“æœæ•°é‡: {result_data['resultInfo'].get('totalResults', '0')}\n\n")
                
                if 'tableData' in result_data and result_data['tableData']:
                    f.write("è¡¨æ ¼æ•°æ®:\n")
                    f.write("-" * 40 + "\n")
                    for i, row in enumerate(result_data['tableData']):
                        f.write(f"è¡Œ {i+1}: {row['text']}\n")
            
            print(f"ğŸ’¾ æ–‡æœ¬æ ¼å¼ç»“æœå·²ä¿å­˜åˆ°: {text_filename}")
            
            # è‡ªåŠ¨å¯¼å‡º table_info æ•°æ®
            print("\nğŸ“Š æ­£åœ¨è‡ªåŠ¨å¯¼å‡º table_info æ•°æ®...")
            self.export_table_info(result_data, applicant_name, "csv")
            self.export_table_info(result_data, applicant_name, "json")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è¡¨å•æ“ä½œç»“æœå¤±è´¥: {e}")

async def main():
    """
    ä¸»å‡½æ•° - é…ç½®å¹¶è¿è¡Œ Playwright è¡¨å•çˆ¬è™«
    """
    # ============================================
    # ğŸ”§ åœ¨è¿™é‡Œé…ç½®ä½ çš„ç™»å½•ä¿¡æ¯
    # ============================================
    
    # ç¤ºä¾‹é…ç½®ï¼ˆè¯·æ ¹æ®å®é™…éœ€æ±‚ä¿®æ”¹ï¼‰
    LOGIN_URL = "https://cpquery.cponline.cnipa.gov.cn/chinesepatent/index"    # æ›¿æ¢ä¸ºå®é™…çš„ç™»å½•é¡µé¢URL
    TARGET_URL = "https://cpquery.cponline.cnipa.gov.cn/chinesepatent/index"  # æ›¿æ¢ä¸ºç™»å½•åè¦çˆ¬å–çš„ç›®æ ‡é¡µé¢URL
    SESSION_DIR = "./my_browser_session"       # ä¼šè¯ä¿å­˜ç›®å½•
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = PlaywrightFormCrawler(
        login_url=LOGIN_URL,
        target_url=TARGET_URL,
        user_data_dir=SESSION_DIR
    )
    
    # æ‰§è¡Œè¡¨å•æ“ä½œ
    company = "é’å²›è¿ˆé‡‘æ™ºèƒ½ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸"
    # company = "é¹°è§’"
    result = await crawler.crawl_with_form_operation(company)
    
    if result:
        print("\nâœ… ä»»åŠ¡å®Œæˆï¼")
        print("ğŸ’¡ æç¤ºï¼šä¸‹æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨ä¿å­˜çš„ä¼šè¯ï¼Œæ— éœ€é‡å¤ç™»å½•")
    else:
        print("\nâŒ ä»»åŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    # å¯åŠ¨çˆ¬è™«
    asyncio.run(main())
